{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxhKiXJ1gwi1",
        "outputId": "48933dbc-1927-43b9-f257-4986baa3952e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.28.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.23.3)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: FastAPI in /usr/local/lib/python3.10/dist-packages (0.115.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.1)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.10/dist-packages (from optimum) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.5.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (24.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.26.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (0.41.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.9.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (0.20.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.16)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install langchain optimum qdrant-client wikipedia FastAPI uvicorn pyngrok\n",
        "!pip install --upgrade pydantic\n",
        "!pip install vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HW5GZanftjT"
      },
      "outputs": [],
      "source": [
        "#GENERATE_MODEL_NAME=\"phatjk/vietcuna-7b-v3-AWQ\"\n",
        "GENERATE_MODEL_NAME=\"vilm/vietcuna-3b-v2\"\n",
        "EMBEDDINGS_MODEL_NAME=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "QDRANT_URL = \"https://d3966086-8c65-4b03-895a-6926e1f83994.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "QDRANT_COLLECTION_NAME = \"Luat_vectordb\"\n",
        "NGROK_STATIC_DOMAIN = \"briefly-knowing-treefrog.ngrok-free.app\"\n",
        "NGROK_TOKEN=          \"2pHsZScewzWnFPxgNOvwnCtfA9R_2J42SPU3YQJhacrYbj4hM\"\n",
        "HUGGINGFACE_API_KEY = \"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\"\n",
        "QDRANT_API_KEY =      \"vkZ3snjz8mkKNj0weWgZxCvnz83ANbesUvYhz7HitC2X-rw_-d4hEg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2lxJrOPoLEH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from optimum.bettertransformer import BetterTransformer\n",
        "import torch\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model_rerank = AutoModelForSequenceClassification.from_pretrained('amberoad/bert-multilingual-passage-reranking-msmarco').to(device)\n",
        "#model_rerank = BetterTransformer.transform(model_rerank)\n",
        "tokenizer_rerank = AutoTokenizer.from_pretrained('amberoad/bert-multilingual-passage-reranking-msmarco')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MonGO3xSz23"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFrBvSkL08Xn"
      },
      "outputs": [],
      "source": [
        "# from langchain.schema.document import Document\n",
        "# from langchain_core.vectorstores import VectorStoreRetriever\n",
        "# from langchain.retrievers import WikipediaRetriever\n",
        "# from typing import List\n",
        "# class RerankRetriever(VectorStoreRetriever):\n",
        "#     vectorstore: VectorStoreRetriever\n",
        "#     def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "#         docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "#         candidates = [doc.page_content for doc in docs]\n",
        "#         queries = [query]*len(candidates)\n",
        "#         features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#         with torch.no_grad():\n",
        "#             scores = model_rerank(**features).logits\n",
        "#             values, indices = torch.sum(scores, dim=1).sort()\n",
        "#             # relevant_docs = docs[indices[0]]\n",
        "#         return [docs[indices[0]],docs[indices[1]]]\n",
        "# class RerankWikiRetriever(VectorStoreRetriever):\n",
        "#     vectorstore: WikipediaRetriever\n",
        "#     def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "#         docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "#         candidates = [doc.page_content for doc in docs]\n",
        "#         queries = [query]*len(candidates)\n",
        "#         features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#         with torch.no_grad():\n",
        "#             scores = model_rerank(**features).logits\n",
        "#             values, indices = torch.sum(scores, dim=1).sort()\n",
        "#             # relevant_docs = docs[indices[0]]\n",
        "#         return [docs[indices[0]],docs[indices[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHmTrDMTx1kP"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.document import Document\n",
        "from langchain_core.vectorstores import VectorStoreRetriever\n",
        "from langchain.retrievers import WikipediaRetriever\n",
        "from typing import List\n",
        "\n",
        "from langchain.schema.document import Document\n",
        "from langchain.schema.retriever import BaseRetriever\n",
        "from typing import List\n",
        "import asyncio\n",
        "\n",
        "class RerankRetriever(BaseRetriever):\n",
        "    \"\"\"Custom retriever that reranks documents\"\"\"\n",
        "\n",
        "    vectorstore: BaseRetriever = Field(description=\"Base vectorstore retriever\")\n",
        "\n",
        "    model_config = {\n",
        "        \"arbitrary_types_allowed\": True,\n",
        "        \"extra\": \"allow\"\n",
        "    }\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "        candidates = [doc.page_content for doc in docs]\n",
        "        queries = [query]*len(candidates)\n",
        "        features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            scores = model_rerank(**features).logits\n",
        "            values, indices = torch.sum(scores, dim=1).sort()\n",
        "        return [docs[indices[0]], docs[indices[1]]]\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        return await asyncio.to_thread(self.get_relevant_documents, query)\n",
        "\n",
        "class RerankWikiRetriever(BaseRetriever):\n",
        "    \"\"\"Custom retriever for Wikipedia that reranks documents\"\"\"\n",
        "\n",
        "    vectorstore: WikipediaRetriever = Field(description=\"Wikipedia retriever\")\n",
        "\n",
        "    model_config = {\n",
        "        \"arbitrary_types_allowed\": True,\n",
        "        \"extra\": \"allow\"\n",
        "    }\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "        candidates = [doc.page_content for doc in docs]\n",
        "        queries = [query]*len(candidates)\n",
        "        features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            scores = model_rerank(**features).logits\n",
        "            values, indices = torch.sum(scores, dim=1).sort()\n",
        "        return [docs[indices[0]], docs[indices[1]]]\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        return await asyncio.to_thread(self.get_relevant_documents, query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRMPAAYpRcMJ"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjHRgM79Pr-c"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import WikipediaRetriever\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from qdrant_client import QdrantClient\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain.chains import RetrievalQA,MultiRetrievalQAChain\n",
        "from langchain.llms import VLLM\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "class LLMServe:\n",
        "    def __init__(self) -> None:\n",
        "      self.embeddings = self.load_embeddings()\n",
        "      self.current_source = \"wiki\"\n",
        "      self.retriever = self.load_retriever(retriever_name = self.current_source,embeddings=self.embeddings)\n",
        "      self.pipe = self.load_model_pipeline(max_new_tokens=300)\n",
        "      self.prompt = self.load_prompt_template()\n",
        "      self.rag_pipeline = self.load_rag_pipeline(llm=self.pipe,\n",
        "                                            retriever=self.retriever,\n",
        "                                            prompt=self.prompt)\n",
        "    def load_embeddings(self):\n",
        "      embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "          model_name=EMBEDDINGS_MODEL_NAME,\n",
        "          api_key = HUGGINGFACE_API_KEY,\n",
        "          #model_kwargs = {'device': \"auto\"}\n",
        "      )\n",
        "      return embeddings\n",
        "\n",
        "    def load_retriever(self,retriever_name,embeddings):\n",
        "      retriever=None\n",
        "      if retriever_name == \"wiki\":\n",
        "        retriever = RerankWikiRetriever(vectorstore = WikipediaRetriever(lang=\"vi\",\n",
        "                                       doc_content_chars_max=800,top_k_results=15))\n",
        "      else:\n",
        "        client = QdrantClient(\n",
        "            url=QDRANT_URL,api_key=QDRANT_API_KEY, prefer_grpc=False\n",
        "        )\n",
        "        db = Qdrant(client=client,\n",
        "                    embeddings=embeddings,\n",
        "                    collection_name=QDRANT_COLLECTION_NAME)\n",
        "\n",
        "        retriever = RerankRetriever(vectorstore = db.as_retriever(search_kwargs={\"k\":15}))\n",
        "\n",
        "      return retriever\n",
        "\n",
        "    def load_model_pipeline(self,max_new_tokens=100):\n",
        "      llm = VLLM(\n",
        "          model=GENERATE_MODEL_NAME,\n",
        "          trust_remote_code=True,  # mandatory for hf models\n",
        "          max_new_tokens=max_new_tokens,\n",
        "            # temperature=1.0,\n",
        "            # top_k=50,\n",
        "            # top_p=0.9,\n",
        "          top_k=10,\n",
        "          top_p=0.95,\n",
        "          temperature=0.4,\n",
        "          dtype=\"half\",\n",
        "          #vllm_kwargs={\"quantization\": \"awq\"}\n",
        "      )\n",
        "      return llm\n",
        "\n",
        "    def load_prompt_template(self):\n",
        "\n",
        "      query_template = \"Bạn là một chatbot thông minh trả lời câu hỏi dựa trên ngữ cảnh (context).\\n\\n### Context:{context} \\n\\n### Human: {question}\\n\\n### Assistant:\"\n",
        "      prompt = PromptTemplate(template=query_template,\n",
        "                        input_variables= [\"context\",\"question\"])\n",
        "      return prompt\n",
        "\n",
        "    def load_rag_pipeline(self,llm,retriever,prompt):\n",
        "      rag_pipeline = RetrievalQA.from_chain_type(\n",
        "      llm=llm, chain_type='stuff',\n",
        "      retriever=retriever,\n",
        "      chain_type_kwargs={\n",
        "      \"prompt\": prompt\n",
        "      },\n",
        "      return_source_documents=True)\n",
        "      return rag_pipeline\n",
        "\n",
        "    def rag(self,source):\n",
        "      if source == self.current_source:\n",
        "        return self.rag_pipeline\n",
        "      else:\n",
        "        self.retriever = self.load_retriever(retriever_name=source,embeddings=self.embeddings)\n",
        "        self.rag_pipeline = self.load_rag_pipeline(llm=self.pipe,\n",
        "                                      retriever=self.retriever,\n",
        "                                      prompt=self.prompt)\n",
        "        self.current_source = source\n",
        "        return self.rag_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmICGMPnNgKb"
      },
      "outputs": [],
      "source": [
        "!pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiTUoHEmQBOo"
      },
      "outputs": [],
      "source": [
        "app = LLMServe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doMVLeI1P-RO"
      },
      "outputs": [],
      "source": [
        "# from typing import Union\n",
        "# from fastapi.middleware.cors import CORSMiddleware\n",
        "# from fastapi.responses import JSONResponse\n",
        "# from fastapi.encoders import jsonable_encoder\n",
        "# from fastapi import FastAPI\n",
        "# origins = [\"*\"]\n",
        "# app_api = FastAPI()\n",
        "# app_api.add_middleware(\n",
        "#     CORSMiddleware,\n",
        "#     allow_origins=origins,\n",
        "#     allow_credentials=True,\n",
        "#     allow_methods=[\"*\"],\n",
        "#     allow_headers=[\"*\"],\n",
        "# )\n",
        "\n",
        "# @app_api.get(\"/\")\n",
        "# def read_root():\n",
        "#     return \"API RAG\"\n",
        "\n",
        "# @app_api.get(\"/rag/{source}\")\n",
        "# async def read_item(source: str, q: str | None = None):\n",
        "#     if q:\n",
        "#         data = app.rag(source=source)(q)\n",
        "#         sources = []\n",
        "#         for docs in data[\"source_documents\"]:\n",
        "#             sources.append(docs.to_json()[\"kwargs\"])\n",
        "#         res = {\n",
        "#             \"result\" : data[\"result\"],\n",
        "#             \"source_documents\":sources\n",
        "#         }\n",
        "#         return JSONResponse(content=jsonable_encoder(res))\n",
        "#     return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIb5IEgjn_5y"
      },
      "outputs": [],
      "source": [
        "from typing import Union, Optional\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.encoders import jsonable_encoder\n",
        "from fastapi import FastAPI, HTTPException\n",
        "\n",
        "# Định nghĩa các nguồn dữ liệu hợp lệ\n",
        "VALID_SOURCES = [\"nttu\", \"wiki\"]\n",
        "\n",
        "origins = [\"*\"]\n",
        "app_api = FastAPI()\n",
        "app_api.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"], # Cho phép tất cả các nguồn\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app_api.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"API RAG is running\"}\n",
        "\n",
        "@app_api.get(\"/rag/{source}\")\n",
        "async def read_item(source: str, q: Optional[str] = None):\n",
        "    # Kiểm tra source có hợp lệ không\n",
        "    if source not in VALID_SOURCES:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=f\"Invalid source. Must be one of: {VALID_SOURCES}\"\n",
        "        )\n",
        "\n",
        "    # Kiểm tra q có giá trị không\n",
        "    if not q:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=\"Query parameter 'q' is required\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Thực hiện truy vấn RAG\n",
        "        # data = app.rag(source=source)(q)\n",
        "\n",
        "#  INFO:     2405:4802:182d:20c0:4480:65c0:d6dd:cac4:0 - \"GET /rag/nttu?q=xin%20ch%C3%A0o HTTP/1.1\" 500 Internal Server Error\n",
        "# <ipython-input-7-d0ef9f03339d>:38: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
        "#   db = Qdrant(client=client,\n",
        "# <ipython-input-15-a883cb622b5a>:42: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
        "#   data = app.rag(source=source)(q)\n",
        "        data = app.rag(source=source).invoke(q)\n",
        "\n",
        "        # Xử lý kết quả\n",
        "        sources = []\n",
        "        for docs in data[\"source_documents\"]:\n",
        "            sources.append(docs.to_json()[\"kwargs\"])\n",
        "\n",
        "        res = {\n",
        "            \"result\": data[\"result\"],\n",
        "            \"source_documents\": sources\n",
        "        }\n",
        "\n",
        "        return JSONResponse(content=jsonable_encoder(res))\n",
        "\n",
        "    except Exception as e:\n",
        "        # Xử lý lỗi\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=f\"An error occurred: {str(e)}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ4Ymo2GySyK"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "ngrok_tunnel = ngrok.connect(8000,domain=NGROK_STATIC_DOMAIN)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app_api, port=8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXthRmfbx-rZ"
      },
      "source": [
        "## fix bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWLuEONCv_Nx"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "\n",
        "# Kết nối tới Qdrant\n",
        "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "\n",
        "# Lấy thông tin collection\n",
        "collection_info = client.get_collection(\"nttu_sotay_vector_db_v1\")\n",
        "print(\"Collection info:\", collection_info)\n",
        "\n",
        "# Lấy một số points để kiểm tra\n",
        "points = client.scroll(\n",
        "    collection_name=\"nttu_sotay_vector_db_v1\",\n",
        "    limit=2  # Lấy 2 điểm đầu tiên\n",
        ")\n",
        "for point in points[0]:\n",
        "    print(\"\\nPoint ID:\", point.id)\n",
        "    print(\"Payload:\", point.payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr53v7v1wBnQ"
      },
      "outputs": [],
      "source": [
        "# # Truy vấn\n",
        "# query = \"Xếp loại học bổng ở trường\"\n",
        "\n",
        "# # Chuyển đổi truy vấn thành vector\n",
        "# query_vector = embeddings.embed_query(query)\n",
        "\n",
        "# # Tìm kiếm trong collection\n",
        "# search_results = client.search(\n",
        "#     collection_name=\"nttu_sotay_vector_db_v1\",\n",
        "#     query_vector=query_vector,\n",
        "#     limit=5  # Số lượng kết quả muốn lấy\n",
        "# )\n",
        "\n",
        "# # In kết quả\n",
        "# for result in search_results:\n",
        "#     print(\"\\nPoint ID:\", result.id)\n",
        "#     print(\"Score:\", result.score)  # Điểm số tương tự\n",
        "#     print(\"Payload:\", result.payload)  # Nội dung và metadata"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}